{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a6ce386",
   "metadata": {},
   "source": [
    "### 5.1.1 Using gpt to generate Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9669a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from generate_text import generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "455ca9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gpt_model import GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b16cdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embeddings): Embedding(50257, 768)\n",
       "  (position_embeddings): Embedding(256, 768)\n",
       "  (drop_embeddings): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNormalization()\n",
       "  (output_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 256,\n",
    "\"emb_dim\": 768,\n",
    "\"n_heads\": 12,\n",
    "\"n_layers\": 12,\n",
    "\"drop_rate\": 0.1,\n",
    "\"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4411926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you 960esame WindsorFE Keith awaitedSer GaelListMine\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tiktoken\n",
    "def text_to_token(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special= {'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text(\n",
    "model=model,\n",
    "idx=text_to_token(start_context, tokenizer),\n",
    "max_tokens=10,\n",
    "context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721511f",
   "metadata": {},
   "source": [
    "### 5.1.2 Calculating text generation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00cfed04",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],[40, 1107, 588]])\n",
    "#Every effort moves, I really like\n",
    "#We want\n",
    "#effort move you, really like chocolate\n",
    "#Meaning for every token we want it to correctly predict the next token\n",
    "targets = torch.tensor([[3626, 6100, 345 ], [1107, 588, 11311]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a604a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0082ab01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ids:\n",
      " tensor([[[13207],\n",
      "         [  552],\n",
      "         [42826]],\n",
      "\n",
      "        [[18236],\n",
      "         [34817],\n",
      "         [ 7055]]])\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1: hole compNetflix\n"
     ]
    }
   ],
   "source": [
    "#Next we find the arg max i.e for every token in each of the 2 examples we find the token with the highest probability\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token ids:\\n\", token_ids)\n",
    "print(f\"Targets batch 1: {token_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"f\" {token_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d45f7",
   "metadata": {},
   "source": [
    "We now want to evaluate this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc52703b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1\n",
      " tensor([5.0549e-05, 2.7952e-05, 8.2801e-06])\n",
      "Target: 2:\n",
      " tensor([1.2945e-05, 3.2755e-05, 5.2184e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0;\n",
    "target_probas1 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
    "print(\"Target: 1\\n\",  target_probas1)\n",
    "text_idx = 1;\n",
    "target_probas2 = probas[text_idx, [0,1,2], targets[text_idx]]\n",
    "print(\"Target: 2:\\n\", target_probas2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2128cd75",
   "metadata": {},
   "source": [
    "We want to maximize the above probs\n",
    "We concatenate these 2 tensors into one and then apply log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a013a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.8926, -10.4850, -11.7017, -11.2548, -10.3265, -12.1633])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas1, target_probas2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "537c0b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.9706)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a31f7718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.9706)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = -1* avg_log_probas\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24761075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape:  torch.Size([2, 3, 50257])\n",
      "Target shape:  torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"Logits shape: \", logits.shape)\n",
    "print(\"Target shape: \", targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd5a625",
   "metadata": {},
   "source": [
    "For the cross_entropy loss function in PyTorch, we want to flatten these tensors\n",
    "by combining them over the batch dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d33a371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits shape:  torch.Size([6, 50257])\n",
      "Flattened targets shape:  torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1 )\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits shape: \", logits_flat.shape)\n",
    "print(\"Flattened targets shape: \", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "684e1639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  tensor(10.9706)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e712d72",
   "metadata": {},
   "source": [
    "### 5.1.3 Training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7db9f523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:  20398\n",
      "total_tokens:  5064\n"
     ]
    }
   ],
   "source": [
    "file_path=\"the-verdict.txt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read();\n",
    "total_characters = len(text_data)\n",
    "total_tokens =len(tokenizer.encode(text_data))\n",
    "print(\"Characters: \", total_characters)\n",
    "print(\"total_tokens: \", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5906b2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18358\n",
      "2040\n",
      "20398\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data= text_data[split_idx:]\n",
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(train_data) + len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab291995",
   "metadata": {},
   "source": [
    "Next, we divide the dataset into a training and a validation set and use the data\n",
    "loaders from text-processing.iypnb to prepare the batches for LLM training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90fbfe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loader:\n",
      "\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "validation loader: \n",
      "\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "from dataloader_v1 import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "print(\"Training loader:\\n\")\n",
    "for x,y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "print(\"validation loader: \\n\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ffad71",
   "metadata": {},
   "source": [
    "Next, we implement a utility function to calculate the cross entropy loss of a given\n",
    "batch returned via the training and validation loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7a1bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, output_batch, device, model):\n",
    "    input_batch = input_batch.to(device)\n",
    "    output_batch = output_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0,1), output_batch.flatten())\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "756b3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model ,device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if (len(data_loader) == 0):\n",
    "        return float('nan')\n",
    "    elif num_batches == None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, output_batch) in enumerate(data_loader):\n",
    "        if (i < num_batches):\n",
    "            loss = calc_loss_batch(input_batch, output_batch, device, model)\n",
    "            total_loss += loss\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69af9fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: tensor(10.9995)\n",
      "Validation loss: tensor(11.0198)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793eb898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
