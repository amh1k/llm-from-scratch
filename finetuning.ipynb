{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de26c576",
   "metadata": {},
   "source": [
    "### Different Categories of fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae28778",
   "metadata": {},
   "source": [
    "The most common ways to fine-tune language models are instruction fine-tuning and\n",
    "classification fine-tuning. Instruction fine-tuning involves training a language model on\n",
    "a set of tasks using specific instructions to improve its ability to understand and exe-\n",
    "cute tasks described in natural language prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfbbeb6",
   "metadata": {},
   "source": [
    "In classification fine-tuning, the model is trained to recognize specefic set of class labels like whether an item is spam or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66726a4",
   "metadata": {},
   "source": [
    "Instruction finetuning model can undertake a wide variety of tasks whereas classification finetuning is specefic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "773cb2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam_collection/SpamCollection.tsv already exists therefore skipping the download\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"spam_collection.zip\"\n",
    "extracted_path= \"spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if (data_file_path.exists()):\n",
    "          print(f\"{data_file_path} already exists therefore skipping the download\")\n",
    "          return\n",
    "      \n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read());\n",
    "            \n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "        \n",
    "    original_file_path=Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "    \n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "    \n",
    "        \n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29e03ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "df = pd.read_csv(data_file_path, sep='\\t', header=None, names=[\"Label\", \"Text\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "556744dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53558edf",
   "metadata": {},
   "source": [
    "We can see that the above dataset is not balanced since it has very few spam texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9b07173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Label                                               Text\n",
      "4307      0  Awww dat is sweet! We can think of something t...\n",
      "4138      0                             Just got to  &lt;#&gt;\n",
      "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
      "4461      0  This is wishing you a great day. Moji told me ...\n",
      "5440      0      Thank you. do you generally date the brothas?\n",
      "...     ...                                                ...\n",
      "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
      "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
      "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567      1  This is the 2nd time we have tried 2 contact u...\n",
      "\n",
      "[1494 rows x 2 columns]\n",
      "Label\n",
      "0    747\n",
      "1    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "    return balanced_df\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "print(balanced_df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e3269",
   "metadata": {},
   "source": [
    "Now splitting the dataset into validation, train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ed563e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    return train_df, validation_df, test_df\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d77ca298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068e4633",
   "metadata": {},
   "source": [
    "### Create dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70bf919",
   "metadata": {},
   "source": [
    "We are wroking with a dataset that contains texts of varying size so we pad all messages to the lenght og the longest message in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5832fbdd",
   "metadata": {},
   "source": [
    "To implement batching, where all messages are padded to the length of the lon-\n",
    "gest message in the dataset, we add padding tokens to all shorter messages. For this\n",
    "purpose, we use \"<|endoftext|>\" as a padding token. However intead of adding token directly we can use the token id corresponding to the end of text token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81bf5cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7167f",
   "metadata": {},
   "source": [
    "We now implement a pytorch dataset class which specefies how data is loaded and processed before the data loaders. For this purpose we define a spam dataset class which handles multiple functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5be202e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset (Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id= 50256):\n",
    "        self.data = pd.read_csv(csv_file);\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
    "        if max_length is None:\n",
    "            self.max_length= self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
    "            \n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index];\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "            \n",
    "        )\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            lenNum = len(encoded_text)\n",
    "            if (lenNum > max_length):\n",
    "                max_length = lenNum\n",
    "                \n",
    "        return max_length\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5476b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset= SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=None\n",
    ")\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71d957b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset= SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=train_dataset.max_length\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=train_dataset.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f082015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0;\n",
    "batch_size= 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "dataset=val_dataset,\n",
    "batch_size=batch_size,\n",
    "num_workers=num_workers,\n",
    "drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "dataset=test_dataset,\n",
    "batch_size=batch_size,\n",
    "num_workers=num_workers,\n",
    "drop_last=False,\n",
    ")\n",
    "\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96eb3041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dfaa906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 1024,\n",
    "\"drop_rate\": 0.0,\n",
    "\"qkv_bias\": True\n",
    "}\n",
    "model_configs = {\n",
    "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c0a3e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mload_weights_into_gpt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_weights_into_gpt\n\u001b[32m      4\u001b[39m model_size = CHOOSE_MODEL.split(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m].lstrip(\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[33m\"\u001b[39m).rstrip(\u001b[33m\"\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m settings, params = \u001b[43mdownload_and_load_gpt2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m model= GPTModel(BASE_CONFIG)\n\u001b[32m      7\u001b[39m load_weights_into_gpt(model, params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml and python/llm-from-scratch/gpt_download.py:38\u001b[39m, in \u001b[36mdownload_and_load_gpt2\u001b[39m\u001b[34m(model_size, models_dir)\u001b[39m\n\u001b[32m     36\u001b[39m     backup_url = os.path.join(backup_base_url, model_size, filename)\n\u001b[32m     37\u001b[39m     file_path = os.path.join(model_dir, filename)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackup_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Load settings and params\u001b[39;00m\n\u001b[32m     41\u001b[39m tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml and python/llm-from-scratch/gpt_download.py:73\u001b[39m, in \u001b[36mdownload_file\u001b[39m\u001b[34m(url, destination, backup_url)\u001b[39m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_attempt_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     74\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.RequestException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ml and python/llm-from-scratch/gpt_download.py:50\u001b[39m, in \u001b[36mdownload_file.<locals>._attempt_download\u001b[39m\u001b[34m(download_url)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_attempt_download\u001b[39m(download_url):\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownload_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     response.raise_for_status()\n\u001b[32m     53\u001b[39m     file_size = \u001b[38;5;28mint\u001b[39m(response.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Length\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/.venv/lib/python3.13/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/.venv/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/.venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/.venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/.venv/lib/python3.13/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/.venv/lib/python3.13/site-packages/urllib3/connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    752\u001b[39m     sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m     server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m    755\u001b[39m     tls_in_tls = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/.venv/lib/python3.13/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m:return: New socket connection.\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venvs/.venv/lib/python3.13/site-packages/urllib3/util/connection.py:60\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m:\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, label empty or too long\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     61\u001b[39m     af, socktype, proto, canonname, sa = res\n\u001b[32m     62\u001b[39m     sock = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/socket.py:977\u001b[39m, in \u001b[36mgetaddrinfo\u001b[39m\u001b[34m(host, port, family, type, proto, flags)\u001b[39m\n\u001b[32m    974\u001b[39m \u001b[38;5;66;03m# We override this function since we want to translate the numeric family\u001b[39;00m\n\u001b[32m    975\u001b[39m \u001b[38;5;66;03m# and socket type values to enum constants.\u001b[39;00m\n\u001b[32m    976\u001b[39m addrlist = []\n\u001b[32m--> \u001b[39m\u001b[32m977\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    978\u001b[39m     af, socktype, proto, canonname, sa = res\n\u001b[32m    979\u001b[39m     addrlist.append((_intenum_converter(af, AddressFamily),\n\u001b[32m    980\u001b[39m                      _intenum_converter(socktype, SocketKind),\n\u001b[32m    981\u001b[39m                      proto, canonname, sa))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from gpt_model import GPTModel\n",
    "from load_weights_into_gpt import load_weights_into_gpt\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "model= GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be46703",
   "metadata": {},
   "source": [
    "We now import the generate text and the mapping functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import generate_text\n",
    "importlib.reload(generate_text)\n",
    "from generate_text import generate_text, token_to_text, text_to_token\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text(\n",
    "model=model,\n",
    "idx=text_to_token(text_1, tokenizer),\n",
    "max_tokens=15,\n",
    "context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4eaffd",
   "metadata": {},
   "source": [
    "### adding the classficiation head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437bfdf5",
   "metadata": {},
   "source": [
    "We must modify the pretrained LLM to prepare it for classification fine-tuning. To do\n",
    "so, we replace the original output layer, which maps the hidden representation to a\n",
    "vocabulary of 50,257, with a smaller output layer that maps to two classes: 0 (“not\n",
    "spam”) and 1 (“spam”), as shown in figure 6.9. We use the same model as before, except\n",
    "we replace the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162bbf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (token_embeddings): Embedding(50257, 768)\n",
      "  (position_embeddings): Embedding(1024, 768)\n",
      "  (drop_embeddings): Dropout(p=0.0, inplace=False)\n",
      "  (transformer_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNormalization()\n",
      "  (output_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00413279",
   "metadata": {},
   "source": [
    "We are making the output layer and the last transformer block and layer norm tunable i.e we are finetuning only these layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad= True\n",
    "    \n",
    "torch.manual_seed(123)\n",
    "num_classes= 2\n",
    "model.output_head= torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG['emb_dim'],\n",
    "    out_features=num_classes\n",
    ")\n",
    "for param in model.transformer_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3502bcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tensor([[5211,  345,  423,  640]])\n",
      "Input dimensions:  torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Input: \", inputs)\n",
    "print(\"Input dimensions: \", inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea0dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5840,  0.9893],\n",
      "         [-3.7231,  7.4521],\n",
      "         [-2.2665,  6.6035],\n",
      "         [-3.5974,  3.9888]]])\n",
      "Output dimensions:  torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs= model(inputs)\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Output dimensions: \", outputs.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5974,  3.9888]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea221424",
   "metadata": {},
   "source": [
    " We previously computed the token ID\n",
    "of the next token generated by the LLM by converting the 50,257 outputs into proba-\n",
    "bilities via the softmax function and then returning the position of the highest proba-\n",
    "bility via the argmax function. We take the same approach here to calculate whether\n",
    "the model outputs a “spam” or “not spam” prediction for a given input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd7307b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5974,  3.9888]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label:  1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label: \", label.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48186f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83dc654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions=0\n",
    "    num_examples= 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches=min(num_batches, len(data_loader))  \n",
    "        \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch= input_batch.to(device)\n",
    "            target_batch= target_batch.to(device)\n",
    "            with torch.no_grad(): \n",
    "                logits= model(input_batch)[:,-1,:]\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions+= ((predicted_labels == target_batch).sum().item())\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return correct_predictions/ num_examples\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "val_loader, model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "test_loader, model, device, num_batches=10\n",
    ")\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c18c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch= target_batch.to(device)\n",
    "    logits= model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203146b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb5925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss is : 2.455\n",
      "Validation loss is : 2.585\n",
      "Test loss is : 2.324\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader( train_loader, model, device, num_batches=5 )\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "print(f\"Training loss is : {train_loss:.3f}\")\n",
    "print(f\"Validation loss is : {val_loss:.3f}\")\n",
    "print(f\"Test loss is : {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005d6328",
   "metadata": {},
   "source": [
    "### Finetuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8a0c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, no_epochs, eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs= [],[],[], []\n",
    "    examples_seen, global_step= 0, -1\n",
    "    for epoch in range(no_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen+= input_batch.shape[0]\n",
    "            global_step += 1\n",
    "            if (global_step % eval_freq == 0):\n",
    "                train_loss, val_loss = evaluate_model(model ,train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"f\"Train loss {train_loss:.3f}, \"f\"Val loss {val_loss:.3f}\")\n",
    "        train_accuracy= calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy=calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss= calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss=calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0a6ca57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.124, Val loss 0.027\n",
      "Ep 1 (Step 000050): Train loss 0.207, Val loss 0.252\n",
      "Ep 1 (Step 000100): Train loss 0.014, Val loss 0.183\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Training completed in 21.75 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "start_time= time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer= torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs= 1\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(model, train_loader, val_loader, optimizer, device,no_epochs=num_epochs, eval_freq=50,eval_iter=5)\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfefe80",
   "metadata": {},
   "source": [
    "We now plot the loss function for training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dce8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "linspace only supports 0-dimensional start and end tensors, but got end with 1 dimension(s).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m epochs_tensor= torch.linspace(\u001b[32m0\u001b[39m, num_epochs, \u001b[38;5;28mlen\u001b[39m(train_accs))\n\u001b[32m     20\u001b[39m examples_seen_tensor= torch.linspace(\u001b[32m0\u001b[39m, examples_seen, \u001b[38;5;28mlen\u001b[39m(train_accs))\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mplot_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples_seen_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_accs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_accs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mplot_values\u001b[39m\u001b[34m(epochs_seen, examples_seen, train_values, val_values, label)\u001b[39m\n\u001b[32m     14\u001b[39m plt.show()\n\u001b[32m     15\u001b[39m epochs_tensor = torch.linspace(\u001b[32m0\u001b[39m, num_epochs, \u001b[38;5;28mlen\u001b[39m(train_losses))\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m examples_seen_tensor = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples_seen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_losses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)\n",
      "\u001b[31mRuntimeError\u001b[39m: linspace only supports 0-dimensional start and end tensors, but got end with 1 dimension(s)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  \n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "examples_val = examples_seen.item() if torch.is_tensor(examples_seen) else examples_seen\n",
    "epochs_loss_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_loss_tensor = torch.linspace(0, examples_val, len(train_losses))\n",
    "plot_values(epochs_loss_tensor, examples_loss_tensor, train_losses, val_losses, label=\"loss\")\n",
    "\n",
    "# 2. Plot Accuracy\n",
    "epochs_acc_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_acc_tensor = torch.linspace(0, examples_val, len(train_accs))\n",
    "plot_values(epochs_acc_tensor, examples_acc_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7887f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_tensor= torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor= torch.linspace(0, examples_seen, len(train_accs))\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs,label=\"accuracy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b0d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e552b3a",
   "metadata": {},
   "source": [
    "### Using llm as spam classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e0b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id= 50256):\n",
    "    model.eval()\n",
    "    input_ids= tokenizer.encode(text)\n",
    "    supported_context_length= model.position_embeddings.weight.shape[1]\n",
    "    input_ids= input_ids[:min(max_length, supported_context_length)]\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor= torch.tensor(input_ids, device= device).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        logits= model(input_tensor)[:, -1, :]\n",
    "    predicted_label =torch.argmax(logits, dim=-1).item()\n",
    "    return \"spam\"if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc78a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = (\n",
    "\"You are a winner you have been specially\"\n",
    "\"selected to receive $1000 cash or a $2000 award.\")\n",
    "print(classify_review(text_1, model, tokenizer, device, max_length=train_dataset.max_length))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
