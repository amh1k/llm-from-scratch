{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de26c576",
   "metadata": {},
   "source": [
    "### Different Categories of fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae28778",
   "metadata": {},
   "source": [
    "The most common ways to fine-tune language models are instruction fine-tuning and\n",
    "classification fine-tuning. Instruction fine-tuning involves training a language model on\n",
    "a set of tasks using specific instructions to improve its ability to understand and exe-\n",
    "cute tasks described in natural language prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfbbeb6",
   "metadata": {},
   "source": [
    "In classification fine-tuning, the model is trained to recognize specefic set of class labels like whether an item is spam or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66726a4",
   "metadata": {},
   "source": [
    "Instruction finetuning model can undertake a wide variety of tasks whereas classification finetuning is specefic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "773cb2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam_collection/SpamCollection.tsv already exists therefore skipping the download\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"spam_collection.zip\"\n",
    "extracted_path= \"spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if (data_file_path.exists()):\n",
    "          print(f\"{data_file_path} already exists therefore skipping the download\")\n",
    "          return\n",
    "      \n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read());\n",
    "            \n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "        \n",
    "    original_file_path=Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "    \n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "    \n",
    "        \n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e03ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd;\n",
    "df = pd.read_csv(data_file_path, sep='\\t', header=None, names=[\"Label\", \"Text\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "556744dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53558edf",
   "metadata": {},
   "source": [
    "We can see that the above dataset is not balanced since it has very few spam texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b07173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Label                                               Text\n",
      "4307      0  Awww dat is sweet! We can think of something t...\n",
      "4138      0                             Just got to  &lt;#&gt;\n",
      "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
      "4461      0  This is wishing you a great day. Moji told me ...\n",
      "5440      0      Thank you. do you generally date the brothas?\n",
      "...     ...                                                ...\n",
      "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
      "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
      "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567      1  This is the 2nd time we have tried 2 contact u...\n",
      "\n",
      "[1494 rows x 2 columns]\n",
      "Label\n",
      "0    747\n",
      "1    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "    return balanced_df\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "print(balanced_df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5e3269",
   "metadata": {},
   "source": [
    "Now splitting the dataset into validation, train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ed563e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    return train_df, validation_df, test_df\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77ca298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068e4633",
   "metadata": {},
   "source": [
    "### Create dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70bf919",
   "metadata": {},
   "source": [
    "We are wroking with a dataset that contains texts of varying size so we pad all messages to the lenght og the longest message in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5832fbdd",
   "metadata": {},
   "source": [
    "To implement batching, where all messages are padded to the length of the lon-\n",
    "gest message in the dataset, we add padding tokens to all shorter messages. For this\n",
    "purpose, we use \"<|endoftext|>\" as a padding token. However intead of adding token directly we can use the token id corresponding to the end of text token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81bf5cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7167f",
   "metadata": {},
   "source": [
    "We now implement a pytorch dataset class which specefies how data is loaded and processed before the data loaders. For this purpose we define a spam dataset class which handles multiple functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be202e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset (Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id= 50256):\n",
    "        self.data = pd.read_csv(csv_file);\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
    "        if max_length is None:\n",
    "            self.max_length= self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_texts = [encoded_text[:self.max_length] for encoded_text in self.encoded_texts]\n",
    "            \n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index];\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "            \n",
    "        )\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            lenNum = len(encoded_text)\n",
    "            if (lenNum > max_length):\n",
    "                max_length = lenNum\n",
    "                \n",
    "        return max_length\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5476b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset= SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=None\n",
    ")\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71d957b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset= SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=train_dataset.max_length\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=train_dataset.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f082015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0;\n",
    "batch_size= 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "dataset=val_dataset,\n",
    "batch_size=batch_size,\n",
    "num_workers=num_workers,\n",
    "drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "dataset=test_dataset,\n",
    "batch_size=batch_size,\n",
    "num_workers=num_workers,\n",
    "drop_last=False,\n",
    ")\n",
    "\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96eb3041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfaa906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "\"vocab_size\": 50257,\n",
    "\"context_length\": 1024,\n",
    "\"drop_rate\": 0.0,\n",
    "\"qkv_bias\": True\n",
    "}\n",
    "model_configs = {\n",
    "\"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "\"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "\"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "\"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c0a3e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-13 11:32:37.451893: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (token_embeddings): Embedding(50257, 768)\n",
       "  (position_embeddings): Embedding(1024, 768)\n",
       "  (drop_embeddings): Dropout(p=0.0, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (transformer): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForwardNetwork(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNormalization()\n",
       "      (norm2): LayerNormalization()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNormalization()\n",
       "  (output_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from gpt_model import GPTModel\n",
    "from load_weights_into_gpt import load_weights_into_gpt\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "model= GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be46703",
   "metadata": {},
   "source": [
    "We now import the generate text and the mapping functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac82dc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import generate_text\n",
    "importlib.reload(generate_text)\n",
    "from generate_text import generate_text, token_to_text, text_to_token\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text(\n",
    "model=model,\n",
    "idx=text_to_token(text_1, tokenizer),\n",
    "max_tokens=15,\n",
    "context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4eaffd",
   "metadata": {},
   "source": [
    "### adding the classficiation head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437bfdf5",
   "metadata": {},
   "source": [
    "We must modify the pretrained LLM to prepare it for classification fine-tuning. To do\n",
    "so, we replace the original output layer, which maps the hidden representation to a\n",
    "vocabulary of 50,257, with a smaller output layer that maps to two classes: 0 (“not\n",
    "spam”) and 1 (“spam”), as shown in figure 6.9. We use the same model as before, except\n",
    "we replace the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "162bbf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (token_embeddings): Embedding(50257, 768)\n",
      "  (position_embeddings): Embedding(1024, 768)\n",
      "  (drop_embeddings): Dropout(p=0.0, inplace=False)\n",
      "  (transformer_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (transformer): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (feed_forward): FeedForwardNetwork(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNormalization()\n",
      "      (norm2): LayerNormalization()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNormalization()\n",
      "  (output_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00413279",
   "metadata": {},
   "source": [
    "We are making the output layer and the last transformer block and layer norm tunable i.e we are finetuning only these layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfe5eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad= True\n",
    "    \n",
    "torch.manual_seed(123)\n",
    "num_classes= 2\n",
    "model.output_head= torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG['emb_dim'],\n",
    "    out_features=num_classes\n",
    ")\n",
    "for param in model.transformer_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3502bcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tensor([[5211,  345,  423,  640]])\n",
      "Input dimensions:  torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Input: \", inputs)\n",
    "print(\"Input dimensions: \", inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53ea0dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5840,  0.9893],\n",
      "         [-3.7231,  7.4521],\n",
      "         [-2.2665,  6.6035],\n",
      "         [-3.5974,  3.9888]]])\n",
      "Output dimensions:  torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs= model(inputs)\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Output dimensions: \", outputs.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61ba966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5974,  3.9888]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea221424",
   "metadata": {},
   "source": [
    " We previously computed the token ID\n",
    "of the next token generated by the LLM by converting the 50,257 outputs into proba-\n",
    "bilities via the softmax function and then returning the position of the highest proba-\n",
    "bility via the argmax function. We take the same approach here to calculate whether\n",
    "the model outputs a “spam” or “not spam” prediction for a given input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fd7307b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5974,  3.9888]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label: \", label.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48186f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e83dc654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions=0\n",
    "    num_examples= 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches=min(num_batches, len(data_loader))  \n",
    "        \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch= input_batch.to(device)\n",
    "            target_batch= target_batch.to(device)\n",
    "            with torch.no_grad(): \n",
    "                logits= model(input_batch)[:,-1,:]\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions+= ((predicted_labels == target_batch).sum().item())\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return correct_predictions/ num_examples\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76b4bd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "val_loader, model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "test_loader, model, device, num_batches=10\n",
    ")\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c18c38",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Function parameters cannot be parenthesized (522471721.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef calc_loss_batch((input_batch, target_batch, model, device)):\u001b[39m\n                        ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m Function parameters cannot be parenthesized\n"
     ]
    }
   ],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch= target_batch.to(device)\n",
    "    logits= model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203146b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb5925",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calc_loss_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     train_loss = \u001b[43mcalc_loss_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     val_loss = calc_loss_loader(val_loader, model, device, num_batches=\u001b[32m5\u001b[39m)\n\u001b[32m      4\u001b[39m     test_loss = calc_loss_loader(test_loader, model, device, num_batches=\u001b[32m5\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mcalc_loss_loader\u001b[39m\u001b[34m(data_loader, model, device, num_batches)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (input_batch, target_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i < num_batches:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         loss = \u001b[43mcalc_loss_batch\u001b[49m(input_batch, target_batch, model, device)\n\u001b[32m     12\u001b[39m         total_loss += loss.item()\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mNameError\u001b[39m: name 'calc_loss_batch' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader( train_loader, model, device, num_batches=5 )\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "print(f\"Training loss is : {train_loss:.3f}\")\n",
    "print(f\"Validation loss is : {val_loss:.3f}\")\n",
    "print(f\"Test loss is : {test_loss:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
